{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1uK0OYfmhZD"
   },
   "source": [
    "# Setup Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1b2JCLFmXih"
   },
   "source": [
    "Import required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fiXI4kSSj3ro"
   },
   "outputs": [],
   "source": [
    "# Setup detectron2\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "import os, cv2, csv, ntpath\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sGGWKDnzmVIY"
   },
   "source": [
    "Global variables and settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j3KNRSoYwENr"
   },
   "outputs": [],
   "source": [
    "path_dir_project = \"/thecube/students/jravagli\"\n",
    "\n",
    "# Paths USED datasets\n",
    "path_dir_datasets = os.path.join(path_dir_project, \"datasets/used\")\n",
    "path_train_dataset = os.path.join(path_dir_datasets, \"train\")\n",
    "path_test_dataset = os.path.join(path_dir_datasets, \"test\")\n",
    "path_train_part_1 = os.path.join(path_train_dataset, \"train-part1\")\n",
    "path_train_part_2 = os.path.join(path_train_dataset, \"train-part2\")\n",
    "path_test_part_1 = os.path.join(path_test_dataset, \"test-part1\")\n",
    "path_test_part_2 = os.path.join(path_test_dataset, \"test-part2\")\n",
    "# Path merged annotation files\n",
    "path_train_ann = os.path.join(path_train_dataset, \"train.txt\")\n",
    "path_test_ann = os.path.join(path_train_dataset, \"test.txt\")\n",
    "# Paths preprocessed datasets\n",
    "path_dir_pp_datasets = os.path.join(path_dir_project, \"datasets/used-pp\")\n",
    "path_pp_train_dataset = os.path.join(path_dir_pp_datasets, \"train\")\n",
    "path_pp_valid_dataset = os.path.join(path_dir_pp_datasets, \"valid\")\n",
    "path_pp_test_dataset = os.path.join(path_dir_pp_datasets, \"test\")\n",
    "# Path preprocessed annotation files\n",
    "path_pp_train_ann = os.path.join(path_dir_pp_datasets, \"train.txt\")\n",
    "path_pp_valid_ann = os.path.join(path_dir_pp_datasets, \"valid.txt\")\n",
    "path_pp_test_ann = os.path.join(path_dir_pp_datasets, \"test.txt\")\n",
    "# Paths model\n",
    "path_model_dir = os.path.join(path_dir_project, \"outputs/detectron-12-epochs\")\n",
    "path_model_weights = os.path.join(path_model_dir, \"model_final.pth\")\n",
    "\n",
    "n_classes = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organize USED dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that read the annotation file of a single event class and append the data to a unique file. At the end of the elaboration this file will contain the path and the annotation of all images in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_annotation_file(path_class_ann, path_out_ann, class_id, path_imgs):\n",
    "    print(f\"Processing annotation file {path_class_ann}\")\n",
    "    image_class = class_id\n",
    "    list_path_imgs = []\n",
    "    with open(path_class_ann) as file:\n",
    "        csv_reader = csv.reader(file, delimiter=' ')\n",
    "        for row in tqdm(csv_reader):\n",
    "            if '.jpg' not in row[0]:\n",
    "                continue\n",
    "            else:\n",
    "                image_name = row[0]\n",
    "                list_path_imgs.append(os.path.join(path_imgs, image_name))\n",
    "\n",
    "    with open(path_out_ann, 'a') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for item in list_path_imgs:\n",
    "            writer.writerow([item, class_id])\n",
    "    \n",
    "    print(f\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process all the train annotation files to create a unique file with image paths and classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean old file\n",
    "if os.path.isfile(path_train_ann):\n",
    "    os.remove(path_train_ann)\n",
    "    print(f\"Old {path_train_ann} deleted\")\n",
    "\n",
    "# Process all the annotation files inside part 1\n",
    "process_annotation_file(os.path.join(path_train_part_1, \"concert_train.txt\"), path_train_ann, 0, path_train_part_1)\n",
    "process_annotation_file(os.path.join(path_train_part_1, \"graduation_train.txt\"), path_train_ann, 1, path_train_part_1)\n",
    "process_annotation_file(os.path.join(path_train_part_1, \"meeting_train.txt\"), path_train_ann, 2, path_train_part_1)\n",
    "process_annotation_file(os.path.join(path_train_part_1, \"mountaintrip_train.txt\"), path_train_ann, 3, path_train_part_1)\n",
    "process_annotation_file(os.path.join(path_train_part_1, \"picnic_train.txt\"), path_train_ann, 4, path_train_part_1)\n",
    "process_annotation_file(os.path.join(path_train_part_1, \"sea_holiday_train.txt\"), path_train_ann, 5, path_train_part_1)\n",
    "process_annotation_file(os.path.join(path_train_part_1, \"ski_holiday_train.txt\"), path_train_ann, 6, path_train_part_1)\n",
    "process_annotation_file(os.path.join(path_train_part_1, \"wedding_train.txt\"), path_train_ann, 7, path_train_part_1)\n",
    "# Process all the annotation files inside part 2\n",
    "process_annotation_file(os.path.join(path_train_part_2, \"concert_train.txt\"), path_train_ann, 0, path_train_part_2)\n",
    "process_annotation_file(os.path.join(path_train_part_2, \"conference_train.txt\"), path_train_ann, 8, path_train_part_2)\n",
    "process_annotation_file(os.path.join(path_train_part_2, \"Exibition_train.txt\"), path_train_ann, 9, path_train_part_2)\n",
    "process_annotation_file(os.path.join(path_train_part_2, \"fashion_train.txt\"), path_train_ann, 10, path_train_part_2)\n",
    "process_annotation_file(os.path.join(path_train_part_2, \"protest_train.txt\"), path_train_ann, 11, path_train_part_2)\n",
    "process_annotation_file(os.path.join(path_train_part_2, \"sport_train.txt\"), path_train_ann, 12, path_train_part_2)\n",
    "process_annotation_file(os.path.join(path_train_part_2, \"theaterdance_train.txt\"), path_train_ann, 13, path_train_part_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process all the test annotation files to create a unique file with image paths and classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean old file\n",
    "if os.path.isfile(path_test_ann):\n",
    "    os.remove(path_test_ann)\n",
    "    print(f\"Old {path_test_ann} deleted\")\n",
    "\n",
    "# Process all the annotation files inside part 1\n",
    "process_annotation_file(os.path.join(path_test_part_1, \"concert_test.txt\"), path_test_ann, 0, path_test_part_1)\n",
    "process_annotation_file(os.path.join(path_test_part_1, \"graduation_test.txt\"), path_test_ann, 1, path_test_part_1)\n",
    "process_annotation_file(os.path.join(path_test_part_1, \"meeting_test.txt\"), path_test_ann, 2, path_test_part_1)\n",
    "process_annotation_file(os.path.join(path_test_part_1, \"mountaintrip_test.txt\"), path_test_ann, 3, path_test_part_1)\n",
    "process_annotation_file(os.path.join(path_test_part_1, \"picnic_test.txt\"), path_test_ann, 4, path_test_part_1)\n",
    "process_annotation_file(os.path.join(path_test_part_1, \"sea_holiday_test.txt\"), path_test_ann, 5, path_test_part_1)\n",
    "process_annotation_file(os.path.join(path_test_part_1, \"ski_holiday_test.txt\"), path_test_ann, 6, path_test_part_1)\n",
    "process_annotation_file(os.path.join(path_test_part_1, \"wedding_test.txt\"), path_test_ann, 7, path_test_part_1)\n",
    "# Process all the annotation files inside part 2\n",
    "process_annotation_file(os.path.join(path_test_part_2, \"concert_test.txt\"), path_test_ann, 0, path_test_part_2)\n",
    "process_annotation_file(os.path.join(path_test_part_2, \"conference_test.txt\"), path_test_ann, 8, path_test_part_2)\n",
    "process_annotation_file(os.path.join(path_test_part_2, \"Exibition_test.txt\"), path_test_ann, 9, path_test_part_2)\n",
    "process_annotation_file(os.path.join(path_test_part_2, \"fashion_test.txt\"), path_test_ann, 10, path_test_part_2)\n",
    "process_annotation_file(os.path.join(path_test_part_2, \"protest_test.txt\"), path_test_ann, 11, path_test_part_2)\n",
    "process_annotation_file(os.path.join(path_test_part_2, \"sport_test.txt\"), path_test_ann, 12, path_test_part_2)\n",
    "process_annotation_file(os.path.join(path_test_part_2, \"theaterdance_test.txt\"), path_test_ann, 13, path_test_part_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vaIY0Iazkp9Y"
   },
   "source": [
    "# Preprocess USED dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QL1-dUrWlGOP"
   },
   "source": [
    "Use the trained Mask R-CNN network for detecting clothes in the USED images. We create a new dataset containing the USED images with the clothes isolated from the background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DBPMs69llp0"
   },
   "source": [
    "Load the Mask R-CNN network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rIZPabwnl3jW"
   },
   "outputs": [],
   "source": [
    "# Use the same configuration used for training, with some changes for the \n",
    "# evaluation\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = ()\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = path_model_weights\n",
    "cfg.SOLVER.IMS_PER_BATCH = 8\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 13\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # Confidence threshold for predictions\n",
    "\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEgulpK6pWsD"
   },
   "source": [
    "Function to load the images names and class from the txt files of the annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_zj2_m5Ipfsc"
   },
   "outputs": [],
   "source": [
    "def read_annotation_file(path_file):\n",
    "    with open(path_file) as f:\n",
    "        list_lines = f.readlines()\n",
    "    \n",
    "    list_images_names = []\n",
    "    list_images_classes = []\n",
    "    for line in list_lines:\n",
    "        splits = line.split(\",\")\n",
    "        list_images_names.append(splits[0].strip())\n",
    "        list_images_classes.append(splits[1].strip())\n",
    "    \n",
    "    return list_images_names, list_images_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQ4vebCOjwxO"
   },
   "source": [
    "Function to preprocess and save the train and validation datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ubX8-Fgtriy_"
   },
   "outputs": [],
   "source": [
    "def preprocess_train_dataset(path_train, path_train_ann, path_pp_train, path_pp_train_ann, path_pp_valid, path_pp_valid_ann):\n",
    "    list_path_images, list_images_classes = read_annotation_file(path_train_ann)\n",
    "\n",
    "    # Read and preprocess all the images inside the dataset\n",
    "    list_pp_train_paths = []\n",
    "    list_pp_train_classes = []\n",
    "    list_pp_train_clothes = []\n",
    "    list_pp_valid_paths = []\n",
    "    list_pp_valid_classes = []\n",
    "    list_pp_valid_clothes = []\n",
    "    for i in tqdm(range(len(list_path_images))):\n",
    "        path_img = list_path_images[i]\n",
    "        img_class = list_images_classes[i]\n",
    "        img_name = ntpath.basename(path_img)\n",
    "\n",
    "        img = cv2.imread(path_img)\n",
    "        if img is not None:\n",
    "            res = predictor(img)\n",
    "            instances = res[\"instances\"].to(\"cpu\")\n",
    "\n",
    "            # Check if the model found clothes in the image\n",
    "            if len(instances):\n",
    "                # About 15% of the images are assigned to the validation dataset\n",
    "                assign_to_valid = np.random.rand() < 0.15\n",
    "                if assign_to_valid:\n",
    "                    path_pp_dataset = path_pp_valid\n",
    "                    list_pp_paths = list_pp_valid_paths\n",
    "                    list_pp_classes = list_pp_valid_classes\n",
    "                    list_pp_clothes = list_pp_valid_clothes\n",
    "                else:\n",
    "                    path_pp_dataset = path_pp_train\n",
    "                    list_pp_paths = list_pp_train_paths\n",
    "                    list_pp_classes = list_pp_train_classes\n",
    "                    list_pp_clothes = list_pp_train_clothes\n",
    "\n",
    "                # Use the instance segmentation masks to crop the clothes area\n",
    "                for pred_mask, pred_box, pred_clothes, i in zip(instances.pred_masks,instances.pred_boxes,\n",
    "                                                                  instances.pred_classes.numpy(), range(1,len(instances))):\n",
    "                    res_img = np.repeat(pred_mask.numpy()[:, :, None], 3, axis=-1)*img\n",
    "                    w = int(pred_box[2] - pred_box[0])\n",
    "                    h = int(pred_box[3] - pred_box[1])\n",
    "                    y = int(pred_box[1])\n",
    "                    x = int(pred_box[0])\n",
    "                    crop_img = res_img[y:y+h, x:x+w]\n",
    "\n",
    "                    # Save the preprocessed image in the folder dedicated to its class\n",
    "                    path_pp = os.path.join(path_pp_dataset, img_class, os.path.splitext(img_name)[0] + f\"-{i}.jpg\")\n",
    "                    list_pp_paths.append(path_pp)\n",
    "                    list_pp_classes.append(img_class)\n",
    "                    list_pp_clothes.append(pred_clothes) # Clothes class predicted by mask-r-cnn\n",
    "\n",
    "                    cv2.imwrite(path_pp, crop_img)\n",
    "\n",
    "    # Save the train annotation file\n",
    "    file_string = \"\"\n",
    "    for i in range(len(list_pp_train_paths)):\n",
    "        file_string += list_pp_train_paths[i] + \",\" + list_pp_train_classes[i] + \",\" + str(list_pp_train_clothes[i]) + \"\\n\"\n",
    "\n",
    "    with open(path_pp_train_ann, \"w\") as f:\n",
    "        f.write(file_string)\n",
    "        \n",
    "    # Save the validation annotation file\n",
    "    file_string = \"\"\n",
    "    for i in range(len(list_pp_valid_paths)):\n",
    "        file_string += list_pp_valid_paths[i] + \",\" + list_pp_valid_classes[i] + \",\" + str(list_pp_valid_clothes[i]) + \"\\n\"\n",
    "\n",
    "    with open(path_pp_valid_ann, \"w\") as f:\n",
    "        f.write(file_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to preprocess and save the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test_dataset(path_dataset, path_ann, path_pp_dataset, path_pp_ann):\n",
    "    list_path_images, list_images_classes = read_annotation_file(path_ann)\n",
    "\n",
    "    # Read and preprocess all the images inside the dataset\n",
    "    list_pp_paths = []\n",
    "    list_pp_classes = []\n",
    "    list_pp_clothes = []\n",
    "    for i in tqdm(range(len(list_path_images))):\n",
    "        path_img = list_path_images[i]\n",
    "        img_class = list_images_classes[i]\n",
    "        img_name = ntpath.basename(path_img)\n",
    "        \n",
    "        img = cv2.imread(path_img)\n",
    "        if img is not None:\n",
    "            res = predictor(img)\n",
    "            instances = res[\"instances\"].to(\"cpu\")\n",
    "\n",
    "            # Check if the model found clothes in the image\n",
    "            if len(instances):\n",
    "                # Use the instance segmentation masks to crop the clothes area\n",
    "                for pred_mask, pred_box, pred_clothes, i in zip(instances.pred_masks,instances.pred_boxes,\n",
    "                                                                  instances.pred_classes.numpy(), range(1,len(instances))):\n",
    "                    res_img = np.repeat(pred_mask.numpy()[:, :, None], 3, axis=-1)*img\n",
    "                    w = int(pred_box[2] - pred_box[0])\n",
    "                    h = int(pred_box[3] - pred_box[1])\n",
    "                    y = int(pred_box[1])\n",
    "                    x = int(pred_box[0])\n",
    "                    crop_img = res_img[y:y+h, x:x+w]\n",
    "\n",
    "                    # Save the preprocessed image in the folder dedicated to its class\n",
    "                    path_pp = os.path.join(path_pp_dataset, img_class, os.path.splitext(img_name)[0] + f\"-{i}.jpg\")\n",
    "                    list_pp_paths.append(path_pp)\n",
    "                    list_pp_classes.append(img_class)\n",
    "                    list_pp_clothes.append(pred_clothes) # Clothes class predicted by mask-r-cnn\n",
    "\n",
    "                    cv2.imwrite(path_pp, crop_img)\n",
    "\n",
    "    # Save the annotation file\n",
    "    file_string = \"\"\n",
    "    for i in range(len(list_pp_paths)):\n",
    "        file_string += list_pp_paths[i] + \",\" + list_pp_classes[i] + \",\" + str(list_pp_clothes[i]) + \"\\n\"\n",
    "\n",
    "    with open(path_pp_ann, \"w\") as f:\n",
    "        f.write(file_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KNvnd1xvw-HM"
   },
   "source": [
    "Create required folders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0U0xJHRgw_rl"
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(path_dir_pp_datasets):\n",
    "    os.mkdir(path_dir_pp_datasets)\n",
    "\n",
    "# Train folders\n",
    "if not os.path.isdir(path_pp_train_dataset):\n",
    "    os.mkdir(path_pp_train_dataset)\n",
    "for i in range(n_classes):\n",
    "    path_dir_class = os.path.join(path_pp_train_dataset, str(i))\n",
    "    if not os.path.isdir(path_dir_class):\n",
    "        os.mkdir(path_dir_class)\n",
    "\n",
    "# Validation folders\n",
    "if not os.path.isdir(path_pp_valid_dataset):\n",
    "    os.mkdir(path_pp_valid_dataset)\n",
    "for i in range(n_classes):\n",
    "    path_dir_class = os.path.join(path_pp_valid_dataset, str(i))\n",
    "    if not os.path.isdir(path_dir_class):\n",
    "        os.mkdir(path_dir_class)\n",
    "\n",
    "# Test folders\n",
    "if not os.path.isdir(path_pp_test_dataset):\n",
    "    os.mkdir(path_pp_test_dataset)\n",
    "for i in range(n_classes):\n",
    "    path_dir_class = os.path.join(path_pp_test_dataset, str(i))\n",
    "    if not os.path.isdir(path_dir_class):\n",
    "        os.mkdir(path_dir_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhiLC0X6TqO5"
   },
   "source": [
    "Patch to make the model work (for some reason sometimes it requires a first manual evaluation, otherwise it raises an error):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "executionInfo": {
     "elapsed": 1483,
     "status": "ok",
     "timestamp": 1619543633147,
     "user": {
      "displayName": "JASON RAVAGLI",
      "photoUrl": "",
      "userId": "01884994422007125599"
     },
     "user_tz": -120
    },
    "id": "U9cT7gKVTouj",
    "outputId": "c20f6c6c-dbfa-498f-8092-df8c2db42fad"
   },
   "outputs": [],
   "source": [
    "# list_images_names, list_images_classes = read_annotation_file(path_train_ann)\n",
    "# path_img = os.path.join(path_train_dataset, list_images_names[0])\n",
    "# img = cv2.imread(path_img)\n",
    "# plt.imshow(img[:, :, ::-1])\n",
    "# plt.show()\n",
    "# res = predictor(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4D6L1gs3o8H8"
   },
   "source": [
    "Preprocess the training and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100,
     "referenced_widgets": [
      "36e445353fb147048f60e11ace874a49",
      "5ed5757d4d75434b88575249f0bf294d",
      "d2c938820a554501b9fb17d77e881260",
      "cdb751763e0740729e202a0b5ed944f1",
      "1a5c162fd00d4741bbc54648fa64c9ab",
      "e3ee3c06c94844f6ab27d10cb283ec0d",
      "f4fe650bfbf840c6bb5818b460aaca63",
      "e234847dad914f62acc11c973b887e0a"
     ]
    },
    "executionInfo": {
     "elapsed": 5270485,
     "status": "ok",
     "timestamp": 1619548936711,
     "user": {
      "displayName": "JASON RAVAGLI",
      "photoUrl": "",
      "userId": "01884994422007125599"
     },
     "user_tz": -120
    },
    "id": "8JNhsOUmj80f",
    "outputId": "881e7f19-4d81-43a7-e3be-41e711c45b39"
   },
   "outputs": [],
   "source": [
    "print(\"Preprocessing training set...\")\n",
    "preprocess_train_dataset(path_train_dataset, path_train_ann, path_pp_train_dataset,\n",
    "                         path_pp_train_ann, path_pp_valid_dataset, path_pp_valid_ann)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLj138aNkdVC"
   },
   "source": [
    "Preprocess the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100,
     "referenced_widgets": [
      "66287b83ada046d88430127aab3cdc83",
      "ca1db57885d9477181ffda6fffa6e2b6",
      "1c43121254244667b76488c6fc789984",
      "38bd884f472c4b208516b5e114912ecc",
      "b65698126f9a411bb2a7511686200004",
      "a21d5de52f75480f946df08cbe134a73",
      "ec23c6c13af74c5d86ce3367f2ed5cb0",
      "3a82fc71356742e6aec3fe9399b1afc7"
     ]
    },
    "executionInfo": {
     "elapsed": 2641579,
     "status": "ok",
     "timestamp": 1619553225172,
     "user": {
      "displayName": "JASON RAVAGLI",
      "photoUrl": "",
      "userId": "01884994422007125599"
     },
     "user_tz": -120
    },
    "id": "T-T40CePkdVD",
    "outputId": "c419bae9-6d32-469c-aff2-79ed05b2341a"
   },
   "outputs": [],
   "source": [
    "print(\"Preprocessing test set...\")\n",
    "preprocess_test_dataset(path_test_dataset, path_test_ann, path_pp_test_dataset,\n",
    "                        path_pp_test_ann)\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOmjvCnYLIqfjDCW6eOnsjs",
   "collapsed_sections": [
    "br7qmfQRmNU8"
   ],
   "name": "U1-USED-preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1a5c162fd00d4741bbc54648fa64c9ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "1c43121254244667b76488c6fc789984": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a21d5de52f75480f946df08cbe134a73",
      "max": 7000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b65698126f9a411bb2a7511686200004",
      "value": 7000
     }
    },
    "220bdee434ce4813ad61b34188bac6fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "36e445353fb147048f60e11ace874a49": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d2c938820a554501b9fb17d77e881260",
       "IPY_MODEL_cdb751763e0740729e202a0b5ed944f1"
      ],
      "layout": "IPY_MODEL_5ed5757d4d75434b88575249f0bf294d"
     }
    },
    "38bd884f472c4b208516b5e114912ecc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a82fc71356742e6aec3fe9399b1afc7",
      "placeholder": "​",
      "style": "IPY_MODEL_ec23c6c13af74c5d86ce3367f2ed5cb0",
      "value": " 7000/7000 [43:59&lt;00:00,  2.65it/s]"
     }
    },
    "3a82fc71356742e6aec3fe9399b1afc7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "55a9fe1eaefc44629781ab354a454d80": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d3573723c1e4bd79dfd48a4729050c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_55a9fe1eaefc44629781ab354a454d80",
      "max": 3500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_220bdee434ce4813ad61b34188bac6fb",
      "value": 3500
     }
    },
    "5ed5757d4d75434b88575249f0bf294d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "66287b83ada046d88430127aab3cdc83": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1c43121254244667b76488c6fc789984",
       "IPY_MODEL_38bd884f472c4b208516b5e114912ecc"
      ],
      "layout": "IPY_MODEL_ca1db57885d9477181ffda6fffa6e2b6"
     }
    },
    "86426d5e45cd4917a05290bffbf9c903": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b8b453ceab3340ff9f692deffe655772",
      "placeholder": "​",
      "style": "IPY_MODEL_a341b27a6ba648a3bdf6f1f3f007dd71",
      "value": " 3500/3500 [22:26&lt;00:00,  2.60it/s]"
     }
    },
    "909e85c5339c4880a5761f80dd1f0855": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5d3573723c1e4bd79dfd48a4729050c4",
       "IPY_MODEL_86426d5e45cd4917a05290bffbf9c903"
      ],
      "layout": "IPY_MODEL_c267190a0fac4aa9bbce53c5acb9fc58"
     }
    },
    "a21d5de52f75480f946df08cbe134a73": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a341b27a6ba648a3bdf6f1f3f007dd71": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b65698126f9a411bb2a7511686200004": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b8b453ceab3340ff9f692deffe655772": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c267190a0fac4aa9bbce53c5acb9fc58": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca1db57885d9477181ffda6fffa6e2b6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cdb751763e0740729e202a0b5ed944f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e234847dad914f62acc11c973b887e0a",
      "placeholder": "​",
      "style": "IPY_MODEL_f4fe650bfbf840c6bb5818b460aaca63",
      "value": " 14000/14000 [1:27:49&lt;00:00,  2.66it/s]"
     }
    },
    "d2c938820a554501b9fb17d77e881260": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e3ee3c06c94844f6ab27d10cb283ec0d",
      "max": 14000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1a5c162fd00d4741bbc54648fa64c9ab",
      "value": 14000
     }
    },
    "e234847dad914f62acc11c973b887e0a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3ee3c06c94844f6ab27d10cb283ec0d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec23c6c13af74c5d86ce3367f2ed5cb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f4fe650bfbf840c6bb5818b460aaca63": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
