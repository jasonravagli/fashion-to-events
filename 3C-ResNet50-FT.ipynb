{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 827,
     "status": "ok",
     "timestamp": 1620384407935,
     "user": {
      "displayName": "JACOPO BARTOLI",
      "photoUrl": "",
      "userId": "09877609771543953448"
     },
     "user_tz": -120
    },
    "id": "XlCuPn6kYiYb"
   },
   "outputs": [],
   "source": [
    "import copy, os, time, shutil\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import sampler, Dataset\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make PyTorch use the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OZkWxIzTYmpy"
   },
   "outputs": [],
   "source": [
    "assert torch.cuda.is_available()\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global variables and settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir_project = \"/thecube/students/jravagli\"\n",
    "path_dir_output = os.path.join(path_dir_project, \"outputs\", \"resnet50-ft\")\n",
    "path_dir_tensorboard = os.path.join(path_dir_output, \"tensorboard\")\n",
    "\n",
    "# Paths datasets\n",
    "path_dir_datasets = os.path.join(path_dir_project, \"datasets\", \"used-pp\")\n",
    "path_train_dataset = os.path.join(path_dir_datasets, \"train\")\n",
    "path_valid_dataset = os.path.join(path_dir_datasets, \"valid\")\n",
    "path_test_dataset = os.path.join(path_dir_datasets, \"test\")\n",
    "# Path annotation files\n",
    "path_train_ann = os.path.join(path_dir_datasets, \"train.txt\")\n",
    "path_valid_ann = os.path.join(path_dir_datasets, \"valid.txt\")\n",
    "path_test_ann = os.path.join(path_dir_datasets, \"test.txt\")\n",
    "# Path models\n",
    "path_models_folder = os.path.join(path_dir_output, \"models\")\n",
    "path_model_ft = os.path.join(path_models_folder, \"resnet50-ft.pth\")\n",
    "path_model_ft_best = os.path.join(path_models_folder, \"resnet50-ft-best.pth\")\n",
    "# Input Path\n",
    "model_path = os.path.join(path_dir_project, \"outputs\",\"resnet50-tl-final\",\"models\",\"resnet50-tl-best.pth\")\n",
    "\n",
    "n_classes = 14\n",
    "img_height = 150\n",
    "img_width = 150\n",
    "\n",
    "batch_size = 64\n",
    "lr_ft = 5e-5\n",
    "weight_decay = 1e-3\n",
    "ft_epochs = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean output dir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(path_dir_output):\n",
    "    shutil.rmtree(path_dir_output)\n",
    "\n",
    "os.mkdir(path_dir_output)\n",
    "os.mkdir(path_dir_tensorboard)\n",
    "os.mkdir(path_models_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure tensorboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(path_dir_tensorboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define data preprocessing operations (apply some data augmentation to the training set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HjPKynnG1RAy"
   },
   "outputs": [],
   "source": [
    "# Normalize the dataset using the ImageNet mean and std\n",
    "# since we will use pretrained networks\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "size = [img_height, img_width]\n",
    "data_transform = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.Normalize(mean,std)\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(size),\n",
    "        transforms.Normalize(mean,std)\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the custom dataset that reads the data from a csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UsedDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.np_data = pd.read_csv(csv_file).to_numpy()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.np_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        path_image = self.np_data[idx, 0]\n",
    "        # Read the image in a PyTorch tensor and squeeze values in [0, 1]\n",
    "        image = read_image(path_image)/255.\n",
    "        label = self.np_data[idx, 1]\n",
    "        clothes = self.np_data[idx, 2]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        sample = {\"image\": image, \"label\": label, \"clothes\": clothes}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = UsedDataset(path_train_ann, transform=data_transform[\"train\"])\n",
    "valid_dataset = UsedDataset(path_valid_ann, transform=data_transform[\"valid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate the samples weights to balance the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_weights_for_balanced_classes(images, nclasses):                        \n",
    "    count = [0] * nclasses                                                      \n",
    "    for item in images:                                                         \n",
    "        count[item[1]] += 1                                                     \n",
    "    weight_per_class = [0.] * nclasses                                      \n",
    "    N = float(sum(count))                                                   \n",
    "    for i in range(nclasses):                                                   \n",
    "        weight_per_class[i] = N/float(count[i])                                 \n",
    "    weight = [0] * len(images)                                              \n",
    "    for idx, val in enumerate(images):                                          \n",
    "        weight[idx] = weight_per_class[val[1]]                                  \n",
    "    return weight   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the data loaders. Use the WeightedRandomSampler to balance the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QhIy0gojeHRc"
   },
   "outputs": [],
   "source": [
    "# For the unbalanced dataset we create a weighted sampler\n",
    "weights_train = make_weights_for_balanced_classes(train_dataset.np_data, n_classes)\n",
    "weights_valid = make_weights_for_balanced_classes(valid_dataset.np_data, n_classes)\n",
    "weights_train = torch.DoubleTensor(weights_train)\n",
    "weights_valid = torch.DoubleTensor(weights_valid)\n",
    "\n",
    "sampler_train = sampler.WeightedRandomSampler(weights_train, len(weights_train))\n",
    "sampler_valid = sampler.WeightedRandomSampler(weights_valid, len(weights_valid))\n",
    "\n",
    "dataloaders = {\n",
    "    \"train\": torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                         num_workers=8, sampler=sampler_train),\n",
    "    \"valid\": torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, \n",
    "                                         num_workers=8, sampler=sampler_valid),\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    \"train\": len(train_dataset),\n",
    "    \"valid\": len(valid_dataset)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a ResNet-50, connect a custom classifier part and load the learned weights obtained by the transfer learning procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=False)\n",
    "\n",
    "# Custom classifier\n",
    "model.fc = nn.Linear(model.fc.in_features, 512)\n",
    "model.relu = nn.ReLU()\n",
    "model.do = nn.Dropout(p=0.5)\n",
    "model.fc_2 = nn.Linear(in_features=512, out_features=n_classes)\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep the first three stages of ResNet frozen during fine tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_trainable_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def freeze_resnet_stages(model):\n",
    "    for param in model.conv1.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.bn1.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.relu.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.maxpool.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.layer1.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.layer2.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.layer3.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Freeze the first two stages of ResNet50 before fine tuning\n",
    "print(f\"Trainable params before freeze: {count_trainable_params(model)}\")\n",
    "freeze_resnet_stages(model)\n",
    "print(f\"Trainable params after freeze: {count_trainable_params(model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_epoch(model, dataloaders, dataset_sizes, criterion, epoch):\n",
    "    train_loss = train_acc = val_loss = val_acc = 0\n",
    "    \n",
    "    for phase in ['train', 'valid']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        curr_batch = 0\n",
    "        for batch_data in tqdm(dataloaders[phase]):\n",
    "            images = batch_data[\"image\"].to(device)\n",
    "            labels = batch_data[\"label\"].to(device)\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(images)\n",
    "                _, preds = torch.max(outputs,1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "        \n",
    "        if phase == \"train\":\n",
    "            train_loss = epoch_loss\n",
    "            train_acc = epoch_acc\n",
    "        else:\n",
    "            val_loss = epoch_loss\n",
    "            val_acc = epoch_acc\n",
    "\n",
    "    return train_loss, train_acc, val_loss, val_acc\n",
    "\n",
    "def train_model(model, criterion, optimizer, dataloaders, dataset_sizes, num_epochs=100):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_val_loss = np.Inf\n",
    "    best_val_acc = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "        \n",
    "        loss, acc, val_loss, val_acc = do_epoch(model, dataloaders, dataset_sizes, criterion, epoch)\n",
    "        \n",
    "        print(f\"Train Loss: {loss:.4f} - Train Acc: {acc:.4f}\")\n",
    "        print(f\"Valid Loss: {val_loss:.4f} - Valid Acc: {val_acc:.4f}\")\n",
    "        \n",
    "        writer.add_scalar('Training loss', loss, epoch)\n",
    "        writer.add_scalar('Training accuracy', acc, epoch)\n",
    "        writer.add_scalar('Valid loss', val_loss, epoch)\n",
    "        writer.add_scalar('Valid accuracy', val_acc, epoch)\n",
    "        \n",
    "        # Save the model at each epoch\n",
    "        torch.save(model.state_dict(), path_model_ft)\n",
    "        \n",
    "        # Save best model monitoring validation loss\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), path_model_ft_best)\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    h = time_elapsed//3600\n",
    "    m = time_elapsed//60 - h*60\n",
    "    s = time_elapsed%60\n",
    "    print(f'Training complete in {h}h {m}m {s}s')\n",
    "    print(f'Best Valid Acc: {best_val_acc:4f}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YQYEvIC17u4-"
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr_ft, weight_decay=weight_decay)\n",
    "\n",
    "model = train_model(model, criterion, optimizer, dataloaders,\n",
    "                    dataset_sizes, num_epochs=ft_epochs)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMFE7pjyZrUYy2q+UQnH8M8",
   "collapsed_sections": [],
   "name": "pytorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
